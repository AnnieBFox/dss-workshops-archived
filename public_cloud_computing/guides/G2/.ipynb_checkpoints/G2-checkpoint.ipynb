{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guide 2: Public Cloud Storage with Microsoft Azure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Public Cloud storage is the service that allow you to keep data on a remote server. You can use your documents but instead of querying them from folders saved in your hardware, they are secure in another place depending from the location you choose for your Azure Storage Account. The main reason for learning how to use storage are that a) it allows for an integrate use of the cloud computing softwares (SaaS) available from the provider and b) it allows to store up 195 GB in each container for an ideally ulimited number of containers (max size 4,7 Terabyte).\n",
    "\n",
    "It is somehow expensive but convenient unless you want to scale your infrastructure every time you need to, incurring in costs that might be avoid in the feature. Let say you have 1 terabyte large folder containing the your last survey, and you want to save it somewhere. With a remote storage you will spend x (todo estimate x) for the next three years compared to buy a new external drive (current price). You can move files from local to remote server inside your Microsoft Azure storage account simply by using applications designed with friendly user interface or using Python.\n",
    "\n",
    "In this tutorial we are going to explain: a) basic of the Microsoft Azure Storage Account service, b) how to use applications for uploading files (i.e. Storage Explorer), c) how to use Azure Software Development Kit (SDK) for Python and its modules functionalities (i.e. azure.storage module).\n",
    "\n",
    "We'll go over the basics of some Microsoft Azure storage account, but we should point out that a *lot* of talented people have given tutorials, and we won't do any better than they have. \n",
    "\n",
    "*TODO Point out some resources and explain why they are good (add links)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [Guide 2: Public Cloud Storage with Microsoft Azure](#Guide-2:-Public-Cloud-Storage-with-Microsoft-Azure)\n",
    "    * [Cloud storage and cloud computing](#Cloud-storage-and-cloud-computing)\n",
    "    * [Azure cloud storage basics](#Azure-Storage-Account-basics)\n",
    "    * [Common Tasks in using Azure cloud storage](#Common-Tasks-in-using-Azure-Storage-Account)\n",
    "    * [Access Azure cloud storage with Storage Explorer UI](#Access-Azure-cloud-storage-with-Storage-Explorer-UI)\n",
    "        * [Set up Storage Explorer](#Set-up-Storage-Explorer)\n",
    "        * [Create BLOB container with Storage Explorer](#Create-BLOB-container-with-Storage-Explorer)\n",
    "        * [Upload BLOBs with Storage Explorer](#Upload-BLOBs-with-Storage-Explorer)\n",
    "    * [Access Azure cloud storage with Python SDK](#Access-Azure-cloud-storage-with-Python-SDK)\n",
    "        * [Azure.storage.blob module overview](#Azure.storage.blob-module-overview)\n",
    "        * [Create BLOB container with Python SDK](#Create-BLOB-container-with-Python-SDK)\n",
    "        * [Upload BLOBs with Python SDK](#Upload-BLOBs-with-Python-SDK)\n",
    "        * [Read BLOBs in container with Python SDK](#Read-BLOBs-in-container-with-Python-SDK)\n",
    "    * [Experiment set up](# broken)\n",
    "        * [Download files](# broken)\n",
    "        * [Upload blob to storage (maybe convert too)](# broken)\n",
    "    * [Recap](#Recap)\n",
    "        *  [What you have learnt](#What-you-have-learnt)\n",
    "        *  [What you will learn next guide](#What-you-will-learn-next-guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud storage and cloud computing\n",
    "\n",
    "Terms like “cloud storage” and “cloud computing” are sometimes used interchangeably. One might be tempted to think they have the same meaning, but this is not truth. They are different services eventhough they derived from the same source: the cloud. The public cloud storage is a system that allows you to store data on the Internet, as you would save on your own computer. Some popular examples are Google Drive, DropBox, or iCloud,  for which the definition of cloud storage remains the same. Cloud computing, on the other hand, is used to work on and complete specified projects. Cloud computing is linked with cloud storage in that you have to move data to the cloud storage before you can make use of cloud computing softwares. In the next part of the guide we are goind to show you how to use the Microsoft's object storage solution called Azure Storage Account using a \n",
    "\n",
    "## Security in the Cloud\n",
    "\n",
    "Add some info about data security in relation to current policy at Harvard https://policy.security.harvard.edu/\n",
    "\n",
    "## Azure Storage Account Basics\n",
    "\n",
    "Azure storage account is Microsoft's solution for the cloud and it stores massive amounts of unstructured data, such as text or binary data. This storage is ideal for serving images or documents directly to a browser, for storing files for distributed access and in our case for analysis by an Azure-hosted service. Objects in the storage can be accessed from anywhere in the world via HTTP or HTTPS. We are going to access blobs storage both via Storage Explore application and URLs using the Azure Storage REST API.\n",
    "\n",
    "As detailed in the Azure storage account documentation, the service uses three resources ([Intro Storage Account](https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blobs-introduction#blob-service-concepts)): your storage account, the containers in the account, and the blobs in a container. The following diagram shows the relationship between these three resources.\n",
    "\n",
    "![public_cloud_storage_concepts](img/public_cloud_storage_concepts.png)\n",
    "\n",
    " - The **Storage Account** provides a unique namespace to store and access your Azure Storage data objects. All objects in a storage account are billed together as a group. By default, the data in your account is available only to you.\n",
    " - The **Container** provides a grouping of a set of blobs. All blobs must be in a container. It is similar to a folder in a file system.\n",
    " - The **Blob**, Binary Large OBject (BLOB), is a collection of binary data stored as a single entity in a database management system [[wiki/Binary_large_object](https://en.wikipedia.org/wiki/Binary_large_object)]. Blobs are typically images, audio or other multimedia objects, though sometimes binary executable code is stored as a blob. Azure Storage offers *three types of blobs*: block blobs, page blobs, and append blobs. Block blobs are ideal for storing text or binary files, such as documents and media files. We are going to use Block blobs.\n",
    "\n",
    "## Common Tasks in using Azure Storage Account\n",
    "\n",
    "*TODO. Explain what is similar in the two settings expained below and motivate when to use one or the other. Manual versus automation. Make an example of manually uploading docs versus using SDK: how long it would take for 1, 10, 100 images? Below a comparison among the two options:\n",
    "\n",
    "|task|UI|SDK|\n",
    "|---|---|---|\n",
    "|create container|---|---|\n",
    "|upload blobs|---|---|\n",
    "|read blobs|---|---|\n",
    "\n",
    "\n",
    "## Access Azure cloud storage with Storage Explorer UI\n",
    "\n",
    "### Set up Storage Explorer\n",
    "\n",
    "Before to upload files to the storage account you deployied in the previous guide (G1), you need to a) download and install the cross platform Storage Explore and b) link the application to your account. Storage Explore allows users to upload blobs to a container to the public cloud. Follow the next steps to install the application and to link your account to Storage Explorer:\n",
    "\n",
    "- Go to https://azure.microsoft.com/en-us/features/storage-explorer/ and select your operating system and download Storage Explorer\n",
    "\n",
    "![download_storage_explorer](img/public_cloud_download_storage_explorer.PNG)\n",
    "\n",
    "- Go to the Downloads folder (or to the folder where you download the app), and double click on the Storage Explorer application to install it. Agree to the terms.\n",
    "\n",
    "![install_storage_explorer](img/public_cloud_install_storage_explorer.PNG)\n",
    "\n",
    "- Once the installation is completed let us launch the application. Go to Azure Dashboard and click on your storage account. On the top bar in the application Click on **`Open in Explorer`**. Choose to open the storage on Storage Explorer.\n",
    "\n",
    "![setup_storage_explorer](img/public_cloud_setup_storage_explorer.PNG)\n",
    "\n",
    "- You are now looking at the Storage Explorer User Interface. On the vertical bar on the left click on the icon with the shape of plug as shown in the snapshoot below to link the application with your storage account.\n",
    "\n",
    "![setup_storage_explorer](img/public_cloud_connect_storage_and_explorer.PNG)\n",
    "\n",
    "- Now it is time to link your storage account using your storage account name and key previously saved:\n",
    "    - Select use a storage account and key, then click on **`Next`**\n",
    "    - Add your storage account name and the key, then click on **`Next`**\n",
    "    - On the connect summary tab, click on **`Connect`**\n",
    "    \n",
    "![public_cloud_upload_file_ABS](img/public_cloud_upload_file_ABS.png)\n",
    "\n",
    "### Create BLOB container with Storage Explorer\n",
    "\n",
    "Cool, you are now connected to your Azure Storage Account. From the user interface you can manage your storage accounts. The tab on the top left allow to connect to your Microsoft Azure account to synchronize all the containers at once. It also allows to manually connect to other storage accounts. The tab on bottom shows your storage account folder and the underpinning folders the most important for us: Blob Containers.\n",
    "\n",
    "![manage_storage](img/public_cloud_manage_storage.PNG)\n",
    "\n",
    "Use Blob Containers to create and manage your containers and to upload your files in the storage. Do the follow:\n",
    "\n",
    "- Right click on **`Blob Containers`** icon, then click on **`Create Blob Containers`** and type in a name for your container. \n",
    "\n",
    "![create_container](img/public_cloud_create_container.PNG)\n",
    "\n",
    "You will see the newly create container in the folder's tree (in my case it is called mynamecontainer). In the container's interface the commands in the top right frame allow you to interact with its contents (BlOBs) and to see some details, while those in the bottom left allows you to delete, create and in general to manage containers. \n",
    "\n",
    "![manage_container](img/azure_storage_manage_container.PNG)\n",
    "\n",
    "The next step set the container to public access. By making the container public you will no need a key to access contents:\n",
    "\n",
    "- Right click on your container, click on **`Public Access Level`**. From the tab that opens, select the option public read access and apply. In the activities tab you will see if you succesfully set the public access. \n",
    "\n",
    "![set_container_public_access](img/public_cloud_set_container_public_access.PNG)\n",
    "\n",
    "\n",
    "### Upload BLOBs with Storage Explorer\n",
    "\n",
    "Write text, Write text, Write text, Write text.\n",
    "\n",
    "Do this:\n",
    "\n",
    "- Click on **`Upload Files`**, then (put some images random in data). To select your file from the folder click on **`[..]`**, select **`Block Blob`** as blob type and then **`Upload`**. To display the BLOBs, double click on the files listed.\n",
    "\n",
    "![upload_blobs](img/public_cloud_upload_blobs.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NAME': 'cloudcomputingplayground',\n",
       " 'API_KEY': 'ItdsjxJIAo0DGyShdBBiQotdEZ+u4SgMhTNQtDtFAY3rupviiam0k/EyxwOA+taDwAaJcNGKADpEjAJN3fBLww=='}"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DELETE THIS CELL BEFORE REALISING THE GUIDE!\n",
    "#retrive keys from my local machine\n",
    "import pickle\n",
    "with open('C:/Users/popor/Desktop/azure_services_keys_v1.1.json', 'rb') as handle:\n",
    "    azure_keys = pickle.load(handle)\n",
    "    \n",
    "azure_keys['STORAGE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access Azure cloud storage with Python SDK\n",
    "### Azure.storage.blob module overview\n",
    "\n",
    "Motivate why we should do this. Because a), b), and c).\n",
    "\n",
    "- Automate repetitive processes \n",
    "- Integration with tool for statistical analysis and machine learning\n",
    "- Extensive documentation to use SDK for Python ([SDK doc](http://azure.github.io/azure-storage-python/ref/azure.storage.blob.html))\n",
    "- Case examples and large community of developers/contributors ([sample code](https://azure.microsoft.com/en-us/resources/samples/?sort=0))\n",
    "\n",
    "https://docs.microsoft.com/en-us/python/api/azure-storage-blob/azure.storage.blob.blockblobservice.blockblobservice?view=azure-python\n",
    "\n",
    "Give a brief presentation of the module functionalities in particular for those used here: \n",
    "\n",
    "    - BlockBlobService(): object to do stuff with Storage Account - IMPORTANT you need it to communicate with storage service\n",
    "    - PublicAccess\n",
    "    - create_container():\n",
    "    - set_container_acl():\n",
    "\n",
    "To accomplish the next tasks, you will need to:  \n",
    "  \n",
    "**_TODO_**\n",
    "show how install Azure software development kit (SDK) for python: \n",
    "- pip install azure (ask Ista which is best)\n",
    "- Azure storage code https://github.com/Azure/azure-storage-python/tree/master/azure-storage-blob #add img mac/windows/linux\n",
    "\n",
    "### Create BLOB container with Python SDK\n",
    "\n",
    "The next piece of code allows you to create a new BLOB container attached to your Storage Account. The code below do the following tasks:\n",
    "\n",
    "- import BlockBlobService and PublicAccess modules fromSDK \n",
    "- retrieve storage name and key\n",
    "- set a new container name\n",
    "- instantiate the BlockBlobService object\n",
    "- call method create_container() from the blob service\n",
    "- call method set_container_acl() from the blob service to set the container access level and set to public access (if you want private, then provide key to the service)\n",
    "\n",
    "Once you completed the cell below run it and check if your container has been created has been created using Storage Explorer UI. You should see a new blob containter with the new container name under your Storage Account. (Note: remember to refresh Storage Explorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from azure library import methods to use storage (make sure to import PublicAccess)\n",
    "from azure.storage.blob import BlockBlobService, PublicAccess\n",
    "\n",
    "# Uncomment this before to release\n",
    "# #retrive your keys\n",
    "# import pickle\n",
    "# with open('../keys/azure_services_keys.json', 'rb') as handle:\n",
    "#     azure_keys = pickle.load(handle)\n",
    "\n",
    "#select storage account name and API key from azure_keys\n",
    "storage_name = azure_keys['STORAGE']['NAME']\n",
    "storage_key = azure_keys['STORAGE']['API_KEY']\n",
    "\n",
    "#create BlockBlockService object to call the the storage account service\n",
    "blob_service = BlockBlobService(account_name= storage_name, account_key=storage_key) \n",
    "\n",
    "#set a name for a new container\n",
    "new_container_name ='myplayground' #erase name here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myplayground BLOB container has been successfully created: True\n"
     ]
    }
   ],
   "source": [
    "#create a new container \n",
    "new_container = blob_service.create_container(new_container_name) \n",
    "\n",
    "#set the BLOB container' acces level to public \n",
    "blob_service.set_container_acl(new_container_name, public_access=PublicAccess.Container)\n",
    "\n",
    "print(\"{} BLOB container has been successfully created: {}\".format(new_container_name, new_container))\n",
    "\n",
    "################################\n",
    "# run this cell once completed #\n",
    "################################\n",
    "\n",
    "#TODO: merge with cell above, but not sure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload BLOBs with Python SDK\n",
    "\n",
    "The next piece of code allows you to upload BLOBs to your newly created container. You can upload images, videos, and tables. The code below do the following tasks:\n",
    "\n",
    "- retrieve directories of the files to upload from your local machine\n",
    "- call method create_blob_from_path() from the blob service to upload file (one at time or all at once). You will need to provide the following arguments:\n",
    "        - container name\n",
    "        - local file name\n",
    "        - path to local file \n",
    "        - file extension\n",
    "- set content type: \n",
    "        - 'image/' for .jpg and .png\n",
    "        - 'audio/x-' for .mp3, .wav\n",
    "        - 'txt/' for .txt, .csv\n",
    "Note: remember to instantiate BlockBlobService to communicate with storage in case you start from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of file stored locally:\n",
      "\t- andrea_porelli.jpg\n",
      "\t- cloud_providers_queries_gt.csv\n",
      "\t- Eisenhower_1952.chunk0.wav\n",
      "\t- ista_zahn.png\n"
     ]
    }
   ],
   "source": [
    "#import library to retrive directories and to set blob contents\n",
    "import os\n",
    "from azure.storage.blob import ContentSettings\n",
    "\n",
    "#set directory to the folder containing the files to upload and get updated directory\n",
    "os.chdir('../../data/playground/')\n",
    "dir_guide = os.getcwd()\n",
    "\n",
    "#store files path, name and extension\n",
    "files_path = []\n",
    "files_name = []\n",
    "files_extension = []\n",
    "\n",
    "#go to the directory and find each file path and file name\n",
    "for root, directories, files in os.walk(dir_guide):\n",
    "    print('List of file stored locally:')\n",
    "    for file in files:\n",
    "        print('\\t-', file)\n",
    "        files_extension.append(file.split('.')[-1])\n",
    "        files_name.append(file)\n",
    "        files_path.append(os.path.join(root,file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to upload blobs\n",
    "def upload_file(blob_service, container, file, path, extension, content_type):\n",
    "        try:\n",
    "            #from the BLOB service call the method using the arguments: container, file path, and file name, and content type\n",
    "            blob_service.create_blob_from_path(container, file, path, content_settings=ContentSettings(content_type= content_type+extension))\n",
    "            print(\"{} BLOB upload status: successful\".format(file))\n",
    "        except:\n",
    "            print(\"{} BLOB upload status: failed\".format(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "andrea_porelli.jpg BLOB upload status: successful\n"
     ]
    }
   ],
   "source": [
    "#upload only the first file in the list \n",
    "local_file_name = files_name[0]\n",
    "local_file_path = files_path[0]\n",
    "file_extension = files_extension[0]\n",
    "\n",
    "#set content type of the file, in this case is a jpg image \n",
    "content_type = 'image/'\n",
    "\n",
    "#use the function to upload blob to the cloud storage\n",
    "upload_file(blob_service, new_container_name, local_file_name, local_file_path, file_extension, content_type) \n",
    "\n",
    "#####################################\n",
    "# try to upload the second element  #\n",
    "# What format is the file?          #\n",
    "#####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cloud_providers_queries_gt.csv BLOB upload status: successful\n",
      "Eisenhower_1952.chunk0.wav BLOB upload status: successful\n",
      "ista_zahn.png BLOB upload status: successful\n"
     ]
    }
   ],
   "source": [
    "#set different content types\n",
    "content_types = ['image/', 'audio/x-', 'txt/']\n",
    "\n",
    "#upload all remaining files having different format at once \n",
    "for path, file, ext in zip(files_path[1:], files_name[1:], files_extension[1:]):\n",
    "    if ext == 'csv' or ext == 'txt':\n",
    "        upload_file(blob_service, new_container_name, file, path, ext, content_types[2])\n",
    "    elif ext == 'mp3' or ext == 'wav':\n",
    "        upload_file(blob_service, new_container_name, file, path, ext, content_types[1])\n",
    "    elif ext == 'jpg' or ext == 'jpeg' or ext == 'png':\n",
    "        upload_file(blob_service, new_container_name, file, path, ext, content_types[0])\n",
    "    else:\n",
    "        raise ValueError('This is not a valid extension. Go to documentation: \\\n",
    "                         http://azure.github.io/azure-storage-python/ref/azure.storage.blob.models.html#azure.storage.blob.models.ContentSettings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what happen if you pass a file whit different image/audio/text format?\n",
    "\n",
    "############################################################################\n",
    "# Suggestion:                                                              #\n",
    "# create a different container for file format. This will avoid to choose  #\n",
    "# from different content type every type you upload multiple files.        #\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read BLOBs in container with Python SDK\n",
    "\n",
    "To access the files in the container you will need to:\n",
    "- call method list_blob() to retrieve a list of the file you uploaded\n",
    "- iterate over the list generator to store BLOBs' name and URLs\n",
    "\n",
    "Note: remember to instantiate BlockBlobService to communicate with storage in case you start from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 BLOBs in your container\n",
      "The BLOBs name are: ['Eisenhower_1952.chunk0.wav', 'andrea_porelli.jpg', 'cloud_providers_queries_gt.csv', 'ista_zahn.png']\n",
      "Below are UTLs for each BLOB:\n",
      "\tBLOB_0: https://cloudcomputingplayground.blob.core.windows.net/myplayground/Eisenhower_1952.chunk0.wav\n",
      "\tBLOB_1: https://cloudcomputingplayground.blob.core.windows.net/myplayground/andrea_porelli.jpg\n",
      "\tBLOB_2: https://cloudcomputingplayground.blob.core.windows.net/myplayground/cloud_providers_queries_gt.csv\n",
      "\tBLOB_3: https://cloudcomputingplayground.blob.core.windows.net/myplayground/ista_zahn.png\n"
     ]
    }
   ],
   "source": [
    "#generate list of files uploaded in your container\n",
    "blobs_uploaded = blob_service.list_blobs(new_container_name)\n",
    "\n",
    "#set BLoB url format\n",
    "blob_url_format = 'https://{0}.blob.core.windows.net/{1}/{2}'\n",
    "\n",
    "#store name and url for each BLOBL in your container\n",
    "blob_name_list = []\n",
    "blob_url_list = []\n",
    "for blob in blobs_uploaded:\n",
    "    blob_name_list.append(blob.name)\n",
    "    blob_url_list.append(blob_url_format.format(blob_service.account_name, new_container_name, blob.name))\n",
    "print(\"There are {} BLOBs in your container\".format(len(blob_name_list)))\n",
    "print(\"The BLOBs name are: {}\".format(blob_name_list))\n",
    "print(\"Below are UTLs for each BLOB:\")\n",
    "for i, blob in enumerate(blob_url_list):\n",
    "    print(\"\\tBLOB_{}: {}\".format(i, blob_url_list[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display Image\n",
    "Using the Let us now print the first image in the blob list. First we have to read the image from the blob storage as byte array and then plot it. To display images from containers into notebook do the following:\n",
    "\n",
    "- import libraries to display image\n",
    "- call method get_blob_to_bytes() to downloads a blob as an array of bytes (it takes blob service instantied before and a blob name as input)\n",
    "- store bytes into local memory (use method .content to extract byte stream from object)\n",
    "- read bytes and display image in the notebook\n",
    "\n",
    "#### Play Audio\n",
    "\n",
    "\n",
    "#### Display Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete BLOB container\n",
    "\n",
    "Once finish poking around is a good practice to delete the storage above if you do not plan to use the files any soon. This reduce your storage costs but also expose you to lost of data. Make sure you have a copy somewhere, if they are of any value. By deliting the container you are going to delete all the contents. We do not need anymore the container, let's delete it! Call from the BlockBlobService object the method delete_container() and pass the name of the container you would like to delete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "playground delition status success: True\n"
     ]
    }
   ],
   "source": [
    "#delete container\n",
    "delete_container = blob_service.delete_container(new_container_name)\n",
    "print(\"{} delition status success: {}\".format(new_container_name, delete_container))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Blob with your notebook\n",
    "\n",
    "\n",
    "To access the files in the container you will need to:\n",
    "- install Azure software development kit (SDK) for python: \n",
    "    - pip install azure. \n",
    "    - Documentation go to  https://github.com/Azure/azure-storage-python/tree/master/azure-storage-blob #add img mac/windows/linux\n",
    "- import BlockBlobService module from the Azure SDK \n",
    "- retrieve storage a) name, b) key, and c) container name \n",
    "- instantiate the BlockBlobService object (IMPORTANT)\n",
    "- call method list_blob() to retrieve a list of the file you uploaded\n",
    "- iterate over the list generator to store BLoBs' name and URLs\n",
    "\n",
    "Let us now print the first image in the blob list. First we have to read the image from the blob storage as byte array and then plot it. To display images from containers into notebook do the following:\n",
    "\n",
    "- import libraries to display image\n",
    "- call method get_blob_to_bytes() to downloads a blob as an array of bytes (it takes blob service instantied before and a blob name as input)\n",
    "- store bytes into local memory (use method .content to extract byte stream from object)\n",
    "- read bytes and display image in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from azure library import methods to use storage (make sure to import PublicAccess)\n",
    "from azure.storage.blob import BlockBlobService, PublicAccess\n",
    "\n",
    "#retrive your keys\n",
    "import pickle\n",
    "with open('../keys/azure_services_keys.json', 'rb') as handle:\n",
    "    azure_keys = pickle.load(handle)\n",
    "\n",
    "#select storage account name and API key from keys\n",
    "storage_name = azure_keys['STORAGE']['NAME']\n",
    "storage_key = azure_keys['STORAGE']['API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#copy the container name \n",
    "container_name = 'mynamecontainer' #add your account name\n",
    "\n",
    "########################\n",
    "#TO FIND CONTAINER NAME:\n",
    "#go to Storage Explorer > your_storage > blob containers > your_container\n",
    "#go to Dashboard > your_storage > Storage Explorer (preview) > your_container\n",
    "#######################\n",
    "\n",
    "\n",
    "\n",
    "################################\n",
    "# run this cell once completed #\n",
    "################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Blob\n",
    "\n",
    "Let us now print the first image in the blob list. First we have to read the image from the blob storage as byte array and then plot it. To display images from containers into notebook do the following:\n",
    "\n",
    "- import libraries to display image\n",
    "- call method get_blob_to_bytes() to downloads a blob as an array of bytes (it takes blob service instantied before and a blob name as input)\n",
    "- store bytes into local memory (use method .content to extract byte stream from object)\n",
    "- read bytes and display image in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import io\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "#allow to print images in this notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read the images as byte array\n",
    "blob_bytes = blob_service.get_blob_to_bytes(container_name, blob_name_list[1])\n",
    "\n",
    "#store byte stream from object \n",
    "blob_bytes_in_memory = io.BytesIO(blob_bytes.content)\n",
    "\n",
    "#read bytes and display image\n",
    "img_bytes = Image.open(blob_bytes_in_memory)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img_bytes);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#BOX\n",
    "#what is inside the blob? byte stream\n",
    "    \n",
    "blob_bytes.content[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Azure Storage Blob Sample - Demonstrate how to use the Blob Storage service. \n",
    "# Blob storage stores unstructured data such as text, binary data, documents or media files. \n",
    "# Blobs can be accessed from anywhere in the world via HTTP or HTTPS. \n",
    "#\n",
    " \n",
    "# Documentation References: \n",
    "#  - What is a Storage Account - http://azure.microsoft.com/en-us/documentation/articles/storage-whatis-account/ \n",
    "#  - Getting Started with Blobs - https://azure.microsoft.com/en-us/documentation/articles/storage-python-how-to-use-blob-storage/\n",
    "#  - Blob Service Concepts - http://msdn.microsoft.com/en-us/library/dd179376.aspx \n",
    "#  - Blob Service REST API - http://msdn.microsoft.com/en-us/library/dd135733.aspx \n",
    "#  - Blob Service Python API - http://azure.github.io/azure-storage-python/ref/azure.storage.blob.html\n",
    "#  - Storage Emulator - http://azure.microsoft.com/en-us/documentation/articles/storage-use-emulator/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Useful links\n",
    "\n",
    "- Azure Storage princing:https://azure.microsoft.com/en-us/pricing/details/storage/\n",
    "\n",
    "\n",
    "- Azure Storage documentation: https://docs.microsoft.com/en-us/azure/storage/ #here you can see language available\n",
    "- Azure Storage quickstart: https://docs.microsoft.com/en-us/azure/storage/blobs/storage-quickstart-blobs-python\n",
    "- Azure Storage SDK: https://github.com/Azure/azure-storage-python/tree/master/azure-storage-blob\n",
    "\n",
    "#### other resources:\n",
    "- https://docs.microsoft.com/en-us/azure/storage/blobs/storage-quickstart-blobs-python\n",
    "-https://github.com/squillace/staging/blob/master/articles/storage/storage-python-how-to-use-blob-storage.md\n",
    "\n",
    "#### Community: active community to try stuff (show how to navigate, select example for Python)\n",
    "\n",
    "https://azure.microsoft.com/en-us/resources/samples/?sort=0\n",
    "https://github.com/Azure/azure-storage-python/tree/master/azure-storage-blob\n",
    "https://github.com/Azure/azure-sdk-for-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload blobs to the container\n",
    "\n",
    "- set a new container name\n",
    "- call method create_container() from the blob service\n",
    "- call method set_container_acl() from the blob service to set the permission container permission. \n",
    "- set public access (if you want private, then provide key to the service)\n",
    "\n",
    "- store bytes into local memory (use method .content to extract byte stream from object)\n",
    "- read bytes and display image in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the BlockBlockService that is used to call the Blob service for the storage account\n",
    "block_blob_service = BlockBlobService(account_name= storage_name, account_key=storage_key) \n",
    "\n",
    "# Create a container called 'quickstartblobs'.\n",
    "container_name =''\n",
    "block_blob_service.create_container(container_name, public_access=PublicAccess.Container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload blobs to the container\n",
    "Blob storage supports block blobs, append blobs, and page blobs. Block blobs are the most commonly used, and that is what is used in this quickstart.\n",
    "\n",
    "To upload a file to a blob, get the full path of the file by joining the directory name and the file name on your local drive. You can then upload the file to the specified path using the create_blob_from_path method.\n",
    "\n",
    "The sample code creates a local file to be used for the upload and download, storing the file to be uploaded as file_path_to_file and the name of the blob as local_file_name. The following example uploads the file to your container called quickstartblobs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Block blobs can be as large as 4.7 TB, and can be anything from Excel spreadsheets to large video files. Page blobs are primarily used for the VHD files used to back IaaS VMs. Append blobs are used for logging, such as when you want to write to a file and then keep adding more information. Most objects stored in Blob storage are block blobs.\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "Clean up resources\n",
    "If you no longer need the blobs uploaded in this quickstart, you can delete the entire container using the delete_container. If the files created are no longer needed, you use the delete_blob method to delete the files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up resources. This includes the container and the temp files\n",
    "block_blob_service.delete_container(container_name)\n",
    "os.remove(full_path_to_file)\n",
    "os.remove(full_path_to_file2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap\n",
    "### What you have learnt\n",
    "\n",
    "- What is cloud storage and when it is useful (a,b,c)\n",
    "- Deploy public cloud storage\n",
    "- Open questions for discussion. Now that you know more about cloud, what do you think about a,b,c?\n",
    "\n",
    "### What you will learn next guide\n",
    "- How to use public cloud services:\n",
    "    - Azure Blob Storage and Cognitive Services using APIs\n",
    "    - Machine Learning Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TODO: MOTIVATE THE USE OF THE NOTEBOOK\n",
    "    - cost of moving file is cheap\n",
    "    - notebook allow for automation\n",
    "\n",
    "\n",
    "- TODO: How much cost the storage? Moving a lot of stuff to and from storage causes \"high bill\"?\n",
    "\n",
    "- TODO: extend uses to: download/scrape more images from social media. upload them into a container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. create_blob_from_path\n",
    "\n",
    "\n",
    "2. create_blob_from_stream\n",
    "3. create_blob_from_bytes \n",
    "4. create_blob_from_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(*) to find url:** Dashboard > Select Cognitive Services to Use > Select Overview > API/refereence or Endpoint: API Service URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrive_blob_list(storage_keys, container_name):\n",
    "    \"\"\" \n",
    "    function to get a list of blobs' URLs\n",
    "    INPUT: - dictionary with storage info. dictionary format: {storage:{storage_name:name,storage_api_key:api_key}}\n",
    "           - container name      \n",
    "    OUTPUT: a list of BLoBs' name and URL\n",
    "    \"\"\"\n",
    "    storage_name = keys['STORAGE']['NAME']\n",
    "    storage_key = keys['STORAGE']['API_KEY']\n",
    "    blob_service = BlockBlobService(storage_name, storage_key)\n",
    "    uploaded_file = blob_service.list_blobs(container_name)\n",
    "    blob_url_format = 'https://{0}.blob.core.windows.net/{1}/{2}'\n",
    "    #store blobs' name and URLs in list\n",
    "    blob_name_list = []\n",
    "    blob_url_list = []\n",
    "    # retrive each blob name\n",
    "    for blob in uploaded_file:\n",
    "        blob_name_list.append(blob.name)\n",
    "        blob_url_list.append(blob_url_format.format(blob_service.account_name, blob_container_name, blob.name))\n",
    "    return blob_name_list, blob_url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get a complete list of images' name and urls\n",
    "retrive_blob_list(azure_keys,'mynamecontainer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Microsoft Cognitive Services APIs with Python\n",
    "\n",
    "#### List of services shown in this tutorial:\n",
    "    \n",
    "- Caption Generation\n",
    "    - Face API to detect facial characteristics\n",
    "    - Computer Vision API to Analyze Image Contents\n",
    "    - Computer Vision API for Optical Character Recognition\n",
    "\n",
    "- Speech Recognition\n",
    "    - Bing Speech Recognition API\n",
    "\n",
    "- Text Analysis using Azure Machine Learning Studio Workshop\n",
    "    - Key Phrases\n",
    "    - Detect Language\n",
    "    - Sentiment Analysis\n",
    "    - Topic Detection\n",
    "\n",
    "\n",
    "- **what are some research applications?**\n",
    "---\n",
    "\n",
    "#### What are you going to learn\n",
    "\n",
    "- use cloud computing services to extract data from images and audio document\n",
    "- use microsoft azure cloud computing services\n",
    "- text analysis: predict and topic detection\n",
    "\n",
    "---\n",
    "\n",
    "#### Requirements\n",
    "\n",
    "**TODO**\n",
    "\n",
    "- list necessary dependencies (pip install azure)\n",
    "- script to install dependecies\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import library to display notebook as HTML\n",
    "import os\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "#path to .ccs style script\n",
    "cur_path = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "new_path = os.path.relpath('..\\\\styles\\\\custom_styles_public_cloud_computing.css', cur_path)\n",
    "\n",
    "#function to display notebook\n",
    "def css():\n",
    "    style = open(new_path, \"r\").read()\n",
    "    return HTML(style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this cell to apply HTML style\n",
    "css()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#TODO\n",
    "#set virtual environment\n",
    "#install requirements\n",
    "#consider adding data storage for ML studio\n",
    "* [Azure Machine Learning Studio](# broken)    \n",
    "    * [Upload file to Machine Learning Studio](# broken)      \n",
    "    * [Explore file inside Machine Learning Studio](# broken)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
